<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reflection 7</title>
</head>
<body>
    <h1>
        Reflection 7
    </h1>
    <h2>
        Sarah Immel
    </h2>
    <h3>
        Sarah graduated from Whitworth with a BA in Human Computer Interaction and English: Writing Studies. Sarah just finished a Master’s in Narrative Futures: Art, Data, Society and is working on a PhD in Designing Responsible Natural Language Processing from The University of Edinburgh.
    </h3>
<p>
    Reflecting on our discussion with Sarah, a computer scientist deeply engaged with the intersection of data and storytelling, it's striking to consider how our digital narratives shape, and are shaped by, the ways we interact with data and technology. Sarah's insights reveal a complex world where data isn't just neutral or passive but actively constructed and shaped by the choices we make as creators and users. One of the ideas Sarah emphasized was how ChatGPT and similar large language models (LLMs) embody this role as storytellers. They don’t just output strings of words; they construct narratives based on patterns and inputs we might overlook or take for granted. Which is an interesting thing to note because do we think they are good story tellers? In this sense, ChatGPT isn’t just a predictive text engine but a lens that can uncover hidden connections, even if its results aren't always critically engaged with the content it generates. This opens up the possibility of gaining new perspectives and the risk of being uncritical, as the outputs can seem coherent yet lack depth.

</p>
<p>
    Another question from Scott was Sarah’s definition of digital humanities. Her definition of digital humanities is applying digital methods to research questions that concern humanity which adds another dimension to our class conversation. In this space, data becomes a lens to understand human experience, but with a catch: we must always recognize the intermediary nature of data. Her reference to “this is not a pipe,” echoing Magritte's famous painting, challenges us to think about representation. Just as a picture of a cat isn’t a cat, data visualizations and digital outputs are never the full reality; they are shaped, simplified, and sometimes misleading representations. The discussion about how we engage with digital platforms revealed that our interactions are framed by algorithms that simplify complexity, often without us noticing. We can open Instagram and consume content without effort, yet we rarely think about the networks, developers, or design decisions that shape that experience. Scott posed an important question: Should we care about this hidden complexity? The answer seemed to point to a balance. While simplification has benefits, there's also value in engaging critically, especially when the narrative influences our attention and choices.

</p>
<p>
    Another compelling topic was the notion of counter-narratives in design. Sarah spoke about the importance of creating spaces for alternative representations, challenging the dominant structures that dictate our digital experiences. This can be abstract, but it emphasizes a need for thoughtful, intentional design that respects user agency and consent. In discussing “modest design” and how to resist dark patterns, she highlighted the potential for digital creators to craft more ethical, humane systems. Sarah’s thoughts on AI and natural language processing also provided another layer to the conversation. She reflected on the initial fear that swept through communities when OpenAI first launched its tools, observing how narratives have since simplified the complexity of AI into discussions of word prediction. However, she noted that AI can offer unique insights, such as recognizing patterns that might be invisible to human observers. This perspective shift can be both powerful and unsettling, as AI-driven narratives aren't always easy to interpret or validate.

</p>
<p>
Next, our discussion turned toward the societal implications of AI, especially in education and creativity. Sarah challenged the idea that AI should only serve utilitarian functions, like automating tasks, instead envisioning a world where technology empowers more creative, human-centric pursuits. A poignant moment was when she referenced a tweet expressing a desire for AI to handle chores so that humans could focus on art. This simple wish raises a profound question: What kind of world do we want AI to help create?
    
</p>
<p>
Sarah concluded with a reflection on the importance of bringing diverse voices into AI and tech conversations, including those who might resist or question these tools. Involving people who don’t typically engage with technology or who prefer creative, less structured expressions can bring valuable perspectives. Creative writers, for example, have a sensitivity to ambiguity and silence, qualities that tech-driven spaces often ignore. This balance between technological advancement and creative potential is crucial. Sarah left us with a thought-provoking vision of what it means to live and design thoughtfully in a world shaped by data. It’s about negotiating what remains unsaid, recognizing the value in potentiality, and being deliberate when we decide to turn ideas into concrete, digital forms. Her reflection challenges us to approach our interactions with technology not just as passive users but as active, reflective participants shaping the narratives of the digital world.
    
</p>
</body>
</html>